model:
  arch: crnn.CRNN
  normalize:
    normalize_type: sync_bn
    bn_group_size: 1
  scale: [2, 2] # T: out sequence length, W: input image's width, T = for i in range(len(scale)): int(W / scale[i]) + shift[i]
  shift: [0, -1]
  kwargs:
    in_channels: 3
dataset:
  train:
    train_root_ceph: ''
    train_source_ceph:
    train_root: /mnt/lustre/share/OCR
    train_source: /mnt/lustre/share/OCR/label/labellist_synth_and_mj_lower.txt
    augmentation:
      kwargs:
        perspective_prob: 0
        perspective_offset: 0.25 # for every corner point, the max offset of x and y direction is perspective_offset * new_h
        new_width_prob: 0
        min_new_width: 0.7
        max_new_width: 1.3
        reverse_prob: 0
    kwargs:
      max_w: 1500 # if image's width (after resize) > max_w, skip this image
      max_label_length: 100
      min_std: 1 # for gray image, if std < min_std, skip it
  val:
    val_root_ceph: ''
    val_source_ceph:
    val_root: /mnt/lustre/share/OCR
    val_source: /mnt/lustre/share/OCR/label/SVT_647_lower.txt
  val_list:
    val_root_list_ceph: []
    val_source_list_ceph: []
    val_root_list: ['/mnt/lustre/share/OCR',
                    '/mnt/lustre/share/OCR',
                    '/mnt/lustre/share/OCR',
                    '/mnt/lustre/share/OCR'
    ]
    val_source_list: ['/mnt/lustre/share/OCR/label/IIIT5k_3000_lower.txt',
                      '/mnt/lustre/share/OCR/label/IC03_867_lower.txt',
                      '/mnt/lustre/share/OCR/label/IC13_1015_lower.txt',
                      '/mnt/lustre/share/OCR/label/SVT_647_lower.txt'
    ]
  dict: /mnt/lustre/share/OCR/dict/synth_dict.txt
  batch_size: 32 # batch size on one GPU
  num_workers: 0
  new_h: 32 # resize image's height to new_h and keep the aspect ratio
  color: True # RGB if True else Gray
solver:
  optimizer:
    type: SGD
    base_lr: 0.01
    kwargs:
      momentum: 0.9
      weight_decay: 0.0001
      nesterov: True
  lr_scheduler:
    lr_mode: step
    milestones: [100000, 130000]
    lr_mults: 0.1
    warmup_from: 0.0001 # linear increase
    warmup_steps: 10000
    max_iter: 140000
  clip_type: norm # norm or value
  max_norm: 10
checkpoint:
  checkpoint_freq: 1000
  checkpoint_path: experiments/crnn/vgg_color/ckpt/150000.pth.tar # finetune from checkpoint_path
  recover: False # True if you want to recover optimizer status from checkpoint_path
  strict: True # whether to strictly enforce that the keys in :attr:`state_dict` match the keys returned by this module's
phase: val
print_freq: 100
val_freq: 1000
work_dir: experiments/crnn/vgg
