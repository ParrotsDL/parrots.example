version: v3.0.0
num_classes: &num_classes 1231

flip: &flip
 type: flip
 kwargs:
   flip_p: 0.5

ms_resize: &ms_resize
 type: keep_ar_resize
 kwargs:
   scales: [640, 672, 704, 736, 768, 800]
   max_size: 1333

resize: &resize
 type: keep_ar_resize
 kwargs:
   scales: [800]
   max_size: 1333

to_tensor: &to_tensor
  type: to_tensor

normalize: &normalize
 type: normalize
 kwargs:
   mean: [0.485, 0.456, 0.406] # ImageNet pretrained statics
   std: [0.229, 0.224, 0.225]

dataset: # Required.
  train:
    dataset:
      type: lvis
      kwargs:
        source: train  # dataset id
        lustre_meta_file: /mnt/lustre/share/DSK/datasets/lvis/lvis_v0.5_train.json
        ceph_meta_file: s3://parrots_model_data/DSK/datasets/lvis/lvis_v0.5_train.json
        has_mask: True
        image_reader:
          type: mix_opencv
          kwargs:
            lustre_image_dir: /mnt/lustre/share/DSK/datasets/mscoco2017/train2017
            ceph_image_dir: s3://parrots_model_data/DSK/datasets/mscoco2017/train2017
            color_mode: RGB
        transformer: [*flip, *ms_resize, *to_tensor, *normalize]
  test:
    dataset:
      type: lvis
      kwargs:
        source: val
        lustre_meta_file: /mnt/lustre/share/DSK/datasets/lvis/lvis_v0.5_val.json
        ceph_meta_file: s3://parrots_model_data/DSK/datasets/lvis/lvis_v0.5_val.json
        image_reader:
          type: mix_opencv
          kwargs:
            lustre_image_dir: /mnt/lustre/share/DSK/datasets/mscoco2017/val2017
            ceph_image_dir: s3://parrots_model_data/DSK/datasets/mscoco2017/val2017
            color_mode: RGB
        transformer: [*resize, *to_tensor, *normalize]
        evaluator:
          type: LVIS               # choices = {'COCO', 'VOC', 'MR'}
          kwargs:
            lustre_gt_file: /mnt/lustre/share/DSK/datasets/lvis/lvis_v0.5_val.json
            ceph_gt_file: s3://parrots_model_data/DSK/datasets/lvis/lvis_v0.5_val.json
            iou_types: [bbox, segm]
  batch_sampler:
    type: aspect_ratio_group
    kwargs:
      sampler:
        type: repeat_factor
        kwargs:
          t: 0.001
          ri_mode: random_round
          pn: 0.5
      batch_size: 1
      aspect_grouping: [1,]
  dataloader:
    type: base
    kwargs:
      num_workers: 4
      alignment: 32


trainer: # Required.
  max_epoch: 25.3736          # 90000 iterations
  test_freq: 25.3736 
  optimizer:                 # optimizer = SGD(params,lr=0.001,momentum=0.9,weight_decay=0.0001)
    type: SGD
    kwargs:
      lr: 0.00125
      momentum: 0.9
      weight_decay: 0.0001
  lr_scheduler:              # lr_scheduler = MultStepLR(optimizer, milestones=[9,14],gamma=0.1)
    warmup_epochs: 0.282          # 1000 iterations of warmup 
    warmup_type: linear
    type: MultiStepLR
    kwargs:
      milestones: [16.9158, 22.5545]     # [60000, 80000]
      gamma: 0.1             # decay rate

saver: # Required.
  save_dir: checkpoints/mask-rcnn-R50-FPN-2x-lvis     # dir to save checkpoints
  lustre_pretrain_model: /mnt/lustre/share/prototype_model_zoo/resnet50_batch1k_epoch100_nesterov_wd0.0001_bn_nowd/checkpoints/ckpt.pth.tar
  ceph_pretrain_model: s3://parrots_model_data/parrots_model_ckpt/prototype_model_zoo/resnet50_batch1k_epoch100_nesterov_wd0.0001_bn_nowd/checkpoints/ckpt.pth.tar
  results_dir: results_dir/mask-rcnn-R50-FPN-2x-lvis  # dir to save detection results. i.e., bboxes, masks, keypoints
  auto_resume: False  # find last checkpoint from save_dir and resume from it automatically
                     # this option has the highest priority (auto_resume > opts > resume_model > pretrain_model)


fp16:
  keep_batchnorm_fp32: True
  scale_factor: dynamic


hooks:
  - type: auto_checkpoint
  - type: train_val_logger
    kwargs: 
      freq: 10
      skip_first_k: 5
      logdir: log
      summary_writer: pavi

net:
  - name: backbone              # backbone = resnet50(frozen_layers, out_layers, out_strides)
    type: pod.models.backbones.resnet50
    kwargs:
      frozen_layers: [0,1]     # layer0...1 is fixed
      out_layers: [1,2,3,4]     # layer1...4, commonly named Conv2...5
      out_strides: [4,8,16,32]  # tell the strides of output features
      normalize:
        type: freeze_bn
      initializer:
        method: msra
      checkpoint: True
  - name: neck
    prev: backbone
    type: pod.models.necks.fpn.FPN
    kwargs:
      outplanes: 256
      start_level: 2
      num_level: 5                # if num_level>len(backbone.out_layers), additional conv with be stacked.
      out_strides: [4,8,16,32,64] # strides of output features. aka., anchor strides for roi_head
      downsample: pool            # method to downsample, for FPN, it's pool, for RetienaNet, it's conv
      upsample: nearest           # method to interp, nearest or bilinear
      initializer:
        method: xavier
  - name: roi_head
    prev: neck
    type: pod.models.heads.roi_head.NaiveRPN
    kwargs:
      feat_planes: 256    # channels of intermediate conv
      num_classes: 2      # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
      initializer:
        method: normal
        std: 0.01
      cfg:
        cls_loss:
          type: softmax_cross_entropy
          kwargs:
            class_dim: -1  # last dim is the class dim
        loc_loss:
          type: smooth_l1_loss
          kwargs:
            sigma: 3.0
        anchor_generator:
          type: hand_craft
          kwargs:
            anchor_ratios: [0.5,1,2]  # anchor strides are provided as feature strides by feature extractor
            anchor_scales: [8]        # scale of anchors relative to feature map
        roi_supervisor:
          type: rpn
          kwargs:
            allowed_border: 0
            matcher:
              type: max_iou
              kwargs:
                positive_iou_thresh: 0.7
                negative_iou_thresh: 0.3
                ignore_iou_thresh:   0.5
                allow_low_quality_match: True
                low_quality_thresh: 0.1  # !this option is not supported yet, but we have future plan
            sampler:
              type: naive
              kwargs:
                batch_size: 256
                positive_percent: 0.5
        train:
          roi_predictor:
            type: base
            kwargs:
              pre_nms_score_thresh: 0.0
              pre_nms_top_n: 2000
              post_nms_top_n: 2000
              roi_min_size: 0
              nms:
                type: naive
                nms_iou_thresh: 0.7
              merger:
                type: rpn
                kwargs:
                  top_n: 2000
        test:
          roi_predictor:
            type: base
            kwargs:
              pre_nms_score_thresh: 0.0
              pre_nms_top_n: 1000
              post_nms_top_n: 1000
              roi_min_size: 0
              nms:
                type: naive
                nms_iou_thresh: 0.7
              merger:
                type: rpn
                kwargs:
                  top_n: 1000
  - name: bbox_head
    prev: neck
    type: pod.models.heads.bbox_head.FC
    kwargs:
      feat_planes: 1024
      num_classes: *num_classes                 # number of classification classes
      initializer:
        method: msra
      cfg:
        cls_loss:
          type: softmax_cross_entropy
          kwargs:
            class_dim: -1  # last dim is the class dim
        loc_loss:
          type: smooth_l1_loss
          kwargs:
            sigma: 1000.0
        fpn:
          fpn_levels: [0,1,2,3]   # indices of fpn features used for this stage. these levels are supposed to be continuous
          base_scale: 56          # target level of a RoI is floor(log2((w*h)**0.5/base_scale))
        roipooling:
          method: 'roialignpool'      # choices=['roialignpool', 'psroipool', 'roipool', 'psroimaskpool']. note that 'psroipool' is for RFCN head
          pool_size: 7
          sampling_ratio: 2           # number of sampling points in each bin. 0 means densely sampled
        bbox_normalize: &bbox_norm
          means: [0, 0, 0, 0]         # statics to normalize localization predictions.
          stds: [0.1, 0.1, 0.2, 0.2]
        share_location: &share_location False         # is share location in bbox regression for all classes
        bbox_supervisor:
          type: faster
          kwargs:
            bbox_normalize: *bbox_norm
            matcher:
              type: max_iou
              kwargs:
                ignore_iou_thresh: 0.5          # Required if provide ignore_regions
                positive_iou_thresh: 0.5
                negative_iou_thresh: 0.5
                allow_low_quality_match: False  # positive if a anchor has highest iou with any gt
            sampler:
              type: naive
              kwargs:
                batch_size: 512
                positive_percent: 0.25
        bbox_predictor:
          type: faster
          kwargs:
            bbox_normalize: *bbox_norm
            share_location: *share_location
            nms:
              type: naive
              nms_iou_thresh: 0.5
            bbox_score_thresh: 0.0
            top_n: 300
  - name: mask_head
    prev: neck
    type: pod.models.heads.mask_head.ConvUp
    kwargs:
      num_classes: *num_classes               # number of classes, 0 for background class
      feat_planes: 256
      num_convs: 4
      deconv_kernel: 2
      initializer:
        method: msra
      cfg:
        mask_loss:
          type: sigmoid_cross_entropy
        fpn:
          fpn_levels: [0,1,2,3]   # indices of fpn features used for this stage. these levels are supposed to be continuous
          base_scale: 56          # target level of a RoI is floor(log2((w*h)**0.5/base_scale))
        roipooling:
          method: 'roialignpool'    # choices=['roialignpool', 'psroipool', 'roipool']. note that 'psroipool' is for RFCN head
          pool_size: 14
          sampling_ratio: 2
        mask_supervisor:
          type: base
          kwargs:
            resample: True            # sampling from rpn proposals; False to use bbox_head sampled results, may be faster
            label_h: 28               # output size of heatmap
            label_w: 28
            sampler:
              type: naive
              kwargs:
                batch_size: 128         # mask batch size of each image
                positive_percent: 1.0   # sample positives only
            matcher:
              type: max_iou
              kwargs:
                positive_iou_thresh: 0.5
                negative_iou_thresh: -1
                allow_low_quality_match: False  # train only. positive if a anchor has highest iou with any gt
                ignore_iou_thresh: -1
        mask_predictor:
          type: base
          kwargs:
            num_classes: *num_classes
            mask_thresh: 0.5
