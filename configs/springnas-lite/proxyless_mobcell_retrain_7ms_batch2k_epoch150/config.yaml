common:
    model:
        arch: proxylessnet
        kwargs:
            scale: 1.0
            channel_dist: [16,32,64,128,256]
            alloc_space: [1,3,3,7,3]
            cell_plan: mobileV2
            alloc_plan: NR
            latency_alpha: 0.00032
            latency_beta: 2
            latency_target: 44

    retrain: True
    with_latency: True

    # Training setting same as mobilenetV2
    augmentation:
        input_size: 224
        test_resize: 256
        colorjitter: [0.2, 0.2, 0.2, 0.1]

    workers: 3
    batch_size: 128 #64

    lr_scheduler:
        type: COSINE

        base_lr: 0.2
        warmup_lr: 0.8
        warmup_steps: 1250
        min_lr: 0.0
        max_iter: 93750

    optimizer:
        type: SGD
        kwargs:
            momentum: 0.9
            weight_decay: 0.00004
            nesterov: True

    no_wd: True
    label_smooth: 0.1

    arch_optimizer:
        type: Adam
        lr: 0.001
        beta1: 0.0
        beta2: 0.999

    val_freq: 1000
    print_freq: 10

    train_root: /mnt/lustre/share/images/train
    train_source: /mnt/lustre/share/images/meta/train.txt
    val_root: /mnt/lustre/share/images/val
    val_source: /mnt/lustre/share/images/meta/val.txt
    arch_root: /mnt/lustre/share/images/train
    arch_source: /mnt/lustre/share/platform/dataset/datasets/nas-lite/proxyless_dataset/vals.txt
