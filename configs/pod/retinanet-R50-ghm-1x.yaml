dataset: # Required.
  type: coco
  train:
    meta_file: /mnt/lustre/share/DSK/datasets/mscoco2017/annotations/instances_train2017.json
    ceph_meta_file: s3://parrots_model_data/DSK/datasets/mscoco2017/annotations/instances_train2017.json
    image_dir: /mnt/lustre/share/DSK/datasets/mscoco2017/train2017
    ceph_image_dir: s3://parrots_model_data/DSK/datasets/mscoco2017/train2017
    flip: True
  test:
    meta_file: /mnt/lustre/share/DSK/datasets/mscoco2017/annotations/instances_val2017.json
    ceph_meta_file: s3://parrots_model_data/DSK/datasets/mscoco2017/annotations/instances_val2017.json
    image_dir: /mnt/lustre/share/DSK/datasets/mscoco2017/val2017
    ceph_image_dir: s3://parrots_model_data/DSK/datasets/mscoco2017/val2017
    flip: False
  has_keypoint: False        # don't use keypoints
  has_mask: False            # don't use segmentations
  aspect_grouping: [1, ]     # use group_sampler when loading dataset
  alignment: 128             # Align size of images to fit FPN. For fpn-faster-rcnn, 32 is enough; for RetinaNet, it's 128.
  scales: [800]              # shorter side of resized image
  max_size: 1333             # longer side of resized image
  pixel_mean: [0.485, 0.456, 0.406] # ImageNet pretrained statics
  pixel_std: [0.229, 0.224, 0.225]
  batch_size: 2
  workers: 4                 # number of workers of dataloader for each process
  evaluator:
    type: COCO
    kwargs:
      gt_file: /mnt/lustre/share/DSK/datasets/mscoco2017/annotations/instances_val2017.json
      ceph_gt_file: s3://parrots_model_data/DSK/datasets/mscoco2017/annotations/instances_val2017.json
      iou_types: [bbox]

trainer: # Required.
  max_epoch: 2               #should be 13     total epochs for the training
  test_freq: 14
  optimizer:                 # optimizer = SGD(params,lr=0.001,momentum=0.9,weight_decay=0.0001)
    type: SGD
    kwargs:
      lr: 0.00125
      momentum: 0.9
      weight_decay: 0.0001
  lr_scheduler:              # lr_scheduler = MultStepLR(optimizer, milestones=[9,14],gamma=0.1)
    warmup_epochs: 1         # set to be 0 to disable warmup. target_lr = init_lr * total_batch_size
    type: MultiStepLR
    kwargs:
      milestones: [8,11]     # epochs to decay lr
      gamma: 0.1             # decay rate

saver: # Required.
  save_dir: checkpoints/retinanet-R50-ghm-1x      # dir to save checkpoints
  pretrain_model: /mnt/lustre/share/DSK/model_zoo/pytorch/imagenet/resnet50-19c8e357.pth
  ceph_pretrain_model: s3://parrots_model_data/parrots_model_ckpt/model_zoo/resnet50-19c8e357.pth
  results_dir: results_dir/retinanet-R50-ghm-1x   # dir to save detection results. i.e., bboxes, masks, keypoints
  #vis_gt:
  #  output_dir: vis_gt
  #vis_dt:
  #  output_dir: vis_dt
  #  bbox_thresh: 0.3


net: # Required.
  - name: backbone            # backbone = resnet50(frozen_layers, out_layers, out_strides)
    type: pod.models.backbones.resnet.resnet50
    kwargs:
      frozen_layers: [0, 1]   # layer0...1 is fixed
      out_layers: [2,3,4]     # layer1...4, commonly named Conv2...5
      out_strides: [8,16,32]  # tell the strides of output features
      deformable: False       # set it as true if using deform for fpn
      normalize:
        type: freeze_bn
      # layer4:               # provide config for layer4 if using deform for fpn, do not use atrous' algorithm
      #   stride: 2
      #   dilation: 1
      #   block: DeformBlock
  - name: neck
    prev: backbone
    type: pod.models.necks.fpn.FPN
    kwargs:
      outplanes: 256
      start_level: 3
      num_level: 5            # if num_level>len(backbone.out_layers), additional conv with be stacked.
      out_strides: [8,16,32,64,128] # strides of output features. aka., anchor strides for roi_head
      downsample: conv        # method to downsample, for FPN, it's pool, for RetienaNet, it's conv
      upsample: nearest       # method to interp, nearest or bilinear
      initializer:
        method: xavier
  - name: roi_head
    prev: neck 
    type: pod.models.heads.roi_head.RetinaSubNet
    kwargs:
      feat_planes: 256        # channels of intermediate conv
      num_classes: 81         # for rpn, it's 2; for RetinaNet, it's 81
      initializer:
        method: normal
        std: 0.01
      cfg:
        focal_loss:
          type: sigmoid
          alpha: 0.25
          gamma: 2.0
          init_prior: 0.01
        ghmc_loss:
          bins: 30
          momentum: 0.75
          loss_weight: 0.33
        ghmr_loss:
          mu: 0.02
          bins: 10
          momentum: 0.7
          loss_weight: 3
        allowed_border: -1            # >=0 for rpn, -1 for retinanet(keep all anchors)
        anchor_ratios: [0.5,1,2]      # anchor strides are provided as feature strides by feature extractor
        anchor_scales: [4, 5.0396842, 6.34960421] # scale of anchors relative to feature map
        roi_min_size: 0               # minimum scale of a valid roi
        nms:
          type: naive
          nms_iou_thresh: -1          # do not nms within each level
        train:
          sampler:
            type: keep_all            # no sampling, keep all positives and negatives
          matcher:
            positive_iou_thresh: 0.5  # train only
            negative_iou_thresh: 0.4  # train only
            ignore_iou_thresh: 0.5    # train only. Required if provide ignore_regions
            allow_low_quality_match: True # an anchor is also positive if it has highest iou with any gt
            iou_thresh: 0.0
        test:
          pre_nms_score_thresh: 0.05  # to reduce computation
          pre_nms_top_n: 6000
          post_nms_top_n: 1000
          across_levels:
            top_n: 100
            nms:
              type: naive
              nms_iou_thresh: 0.5     # Required in RetinaNet. DO not nms in FPN across levels 
