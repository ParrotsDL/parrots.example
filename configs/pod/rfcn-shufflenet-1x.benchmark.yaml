dataset: # Required.
  type: pascal_voc
  class_names: [
        "__background__",
        "aeroplane", "bicycle", "bird", "boat",
        "bottle", "bus", "car", "cat", "chair",
        "cow", "diningtable", "dog", "horse",
        "motorbike", "person", "pottedplant",
        "sheep", "sofa", "train", "tvmonitor"]
  train:
    meta_file: /mnt/lustre/share/DSK/datasets/VOC07+12/ImageSets/Main/trainval.txt
    image_dir: /mnt/lustre/share/DSK/datasets/VOC07+12
    flip: True
  test:
    meta_file: /mnt/lustre/share/DSK/datasets/VOC07+12/ImageSets/Main/test.txt
    image_dir: /mnt/lustre/share/DSK/datasets/VOC07+12
    flip: False
  aspect_grouping: [1, ]
  alignment: 1        # Align size of images to fit FPN. For fpn-faster-rcnn, 32 is enough; for RetinaNet, it's 128.
  scales: [600]       # shorter side of resized image
  max_size: 1000      # longer side of resized image
  pixel_mean: [0.485, 0.456, 0.406] # ImageNet pretrained statics
  pixel_std: [0.229, 0.224, 0.225]
  batch_size: 2 
  workers: 4          # number of workers of dataloader for each process
  evaluator:
    type: VOC         # VOC-style metric 
    kwargs:
      gt_file: /mnt/lustre/share/DSK/datasets/VOC07+12/ImageSets/Main/test.txt  # testset image ids
      iou_thresh: 0.5 # mAP0.5


trainer: # Required.
  max_epoch: 0        # should be 18   total epochs for the training
  test_freq: 1
  optimizer:          # optimizer = SGD(params,lr=0.001,momentum=0.9,weight_decay=0.0001)
    type: SGD
    kwargs:
      lr: 0.00125
      momentum: 0.9
      weight_decay: 0.0001
  lr_scheduler:       # lr_scheduler = MultStepLR(optimizer, milestones=[9,14],gamma=0.1)
    warmup_epochs: 1  # set to be 0 to disable warmup. target_lr = init_lr * total_batch_size
    type: MultiStepLR
    kwargs:
      milestones: [15,17] # epochs to decay lr
      gamma: 0.1          # decay rate

saver: # Required.
  save_dir: checkpoints/rfcn-shufflenet-1x     # dir to save checkpoints
  pretrain_model: /mnt/lustre/share/DSK/model_zoo/pytorch/imagenet/resnet101-5d3b4d8f.pth
  pretrain_model: /mnt/lustre/share/DSK/model_zoo/pytorch/imagenet/shufflenet_v2/shufflenetv2_x1.0_top168.pth.tar
  results_dir: results_dir/rfcn-shufflenet-1x  # dir to save detection results. i.e., bboxes, masks, keypoints
  #vis_dt:    # visualize detection results
  #    output_dir: vis_dt
  #    bbox_thresh: 0.3
  #vis_gt:    # visualize ground truth
  #    output_dir: vis_gt


#do not use fp16 for RFCN
#fp16:
#  scale_factor: 1024

net: # Required.
  - name: backbone
    type: pod.models.backbones.shufflenet.shufflenetv2
    kwargs:
      out_strides: [16]  # tell the strides of output features
      c4_output: true
      width_mult: 1.0
      bn:
        freeze: True
  - name: roi_head
    prev: backbone
    type: pod.models.heads.roi_head.NaiveRPN
    kwargs:
      feat_planes: 512      # channels of intermediate conv
      num_classes: 2        # for rpn, it's 2; for RetinaNet, it's 81
      initializer:
        method: normal
        std: 0.01
      cfg:
        cls_loss: softmax
        anchor_ratios: [0.5,1,2]    # anchor strides are provided as feature strides by feature extractor
        anchor_scales: [8,16,32]    # scale of anchors relative to feature map
        nms:
          type: naive
          nms_iou_thresh: 0.7       # nms thresh. Within each level if FPN
        roi_min_size: 0             # minimum scale of a valid roi
        allowed_border: 0
        train:
          matcher: # train only
            ignore_iou_thresh: 0.5        # train only. Required if provide ignore_regions
            positive_iou_thresh: 0.7      # train only
            negative_iou_thresh: 0.3      # train only
            allow_low_quality_match: True # train only. positive if a anchor has highest iou with any gt 
          sampler: # train only
            type: 'naive'
            batch_size: 256               # train only, batch size of sampled anchors of each image
            positive_percent: 0.5         # train only, number of positives in sampled anchors
          pre_nms_score_thresh: 0.00      # to reduce computation
          pre_nms_top_n: 12000      # number of rois before nms. (within each level if fpn)
          post_nms_top_n: 2000      # number of rois after nms. (within each level if fpn)
        test:
          pre_nms_score_thresh: 0.0 # to reduce computation
          pre_nms_top_n: 6000
          post_nms_top_n: 300
  - name: bbox_head
    prev: backbone
    type: pod.models.heads.bbox_head.RFCN
    kwargs:
      feat_planes: 1024
      num_classes: 21             # number of classification classes
      initializer:
        method: msra
      cfg:
        smooth_l1_sigma: 1.0      # set as 1000.0 to use L1-loss for bbox head
        roipooling:
          method: 'psroipool'     # choices=['roialignpool', 'psroipool', 'roipool']. note that 'psroipool' is for RFCN head
          pool_size: 7
        bbox_normalize:
          means: [0, 0, 0, 0]     # statics to normalize localization predictions.
          stds: [0.1, 0.1, 0.2, 0.2]
        share_location: False     # is share location in bbox regression for all classes
        train:
          matcher: # train only
            ignore_iou_thresh: 0.5          # train only. Required if provide ignore_regions
            positive_iou_thresh: 0.5        # train only
            negative_iou_thresh: 0.5        # train only
            allow_low_quality_match: False  # train only. positive if a anchor has highest iou with any gt 
          sampler: # train only
            type: 'naive'
            batch_size: 512         # train only, rois batch size of each image
            positive_percent: 0.25  # train only
        test:
          nms:
            type: naive
            nms_iou_thresh: 0.3     # test only
          bbox_score_thresh: 0.0    # test only
          top_n: 100                # test only, number of bboxes to keep
