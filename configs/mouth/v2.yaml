# Author: baichen@sensetime.com

### Data Process (start)


# landmark path
landmark_path: /mnt/lustrenew/share/zhuhao/littleprince/datasets/Anchor/Crop_256_256/landmarks_name
# image path
image_path: /mnt/lustrenew/share/zhuhao/littleprince/datasets/Anchor/Crop_256_256/images
# data path
data_root: /mnt/lustre/share_data/maxiaoming/mouth/Anchor_0427   #/mnt/lustre/share/wangyuxin1/Anchor_0427
ceph_root: s3://parrots_model_data/mouth/Anchor_0427
# width of the heatmap face
heatmap_width: 256
# height of the heatmap face
heatmap_height: 256
# width of the mask face (i.e., the crop face)
crop_face_width: 70
# height of the mask face (i.e., the crop face)
crop_face_height: 110
# start index of X in the masked face
start_x: 120
# end index of X in the masked face
end_x: 236
# start index of Y in the masked face
start_y: 30
# end index of Y in the masked face
end_y: 226
# the category of data to process [train/test/all]
category: all

### Data Process (end)


### Training & Testing (start)


## logger options
# frequency to save output images during training
image_display_iter: 500
# frequency to display image at each time
image_display_num: 4
# frequency to save trained models
snapshot_save_iter: 5000
# frequency to draw curves, at the same time test on validation set
draw_curves_iter: 10000

## model_options
# used trainer F means face generator (from mouth shape)
trainer: H2F

## phoneme to landmark network settings
lstm:
  # dimensions of ouput of LSTM node
  node_dim: 60
  # layers of LSTM
  layer_num: 3
  # time step for LSTM
  time_dim: 30
  # FC dimensions
  fc_dim: 256
## Unet settings
# network configurations
unet:
  nc_input_x: 3
  nc_input_y: 39
  nc_output: 3
  ngf: 64
# audio dimensions
audio_dim: 134

## optimization options
# maximum number of training epochs
max_epoch: 20
# batch size
batch_size: 4
# margin for contrastive loss
margin: 2
# the rate of using the shuffle masked face
# set 0.0 will only use shuffled data
masked_face_aligned_rate: 0.0
# weight decay
weight_decay: 0.0001
# Adam parameter beta1
beta1: 0.5
# Adam parameter beta2
beta2: 0.999
# initialization [gaussian/kaiming/xavier/orthogonal]
init: kaiming
# initial learning rate
lr: 0.001
# learning rate scheduler
lr_policy: step
# frequency to decay learning rate
step_size: 20000
# magnitude to decay learning rate
gamma: 0.8
# weight for face reconstruction loss
recon_w: 1
# weight for gan adversarial loss
gan_w: 10
# weight for vgg loss
vgg_w: [1, 1, 1, 1]
# contrastive loss for the discriminator
dis_weight_of_face_shuffle: 1
# path of vgg16 weights path
vgg_model_path: ./models/mouth_inpaint_network/vgg_model/vgg16.weight
# pavi task name
task_name: mouth_v2

## dataset option
# worker threads
num_workers: 12
# use memory cached
use_mc: False

### Training & Testing (end)
