# Author: baichen@sensetime.com

### Data Process (start)


# landmark path
landmark_path: /mnt/lustrenew/share/zhuhao/littleprince/datasets/Anchor/Crop_256_256/landmarks_name
# image path
image_path: /mnt/lustrenew/share/zhuhao/littleprince/datasets/Anchor/Crop_256_256/images
# data path
data_root: ../dataset/2d/h2f/dataset
# width of the heatmap face
heatmap_width: 256
# height of the heatmap face
heatmap_height: 256
# width of the mask face (i.e., the crop face)
crop_face_width: 70
# height of the mask face (i.e., the crop face)
crop_face_height: 110
# the category of data to process [train/test/all]
category: all

### Data Process (end)


### Training & Testing (start)


## logger options
# frequency to save output images during training
image_display_iter: 500
# frequency to display image at each time
image_display_num: 4
# frequency to save trained models
snapshot_save_iter: 5000
# frequency to draw curves, at the same time test on validation set
draw_curves_iter: 10000

## model_options
# used trainer F means face generator (from mouth shape)
trainer: H2F

## Unet settings
# network configurations
unet:
  nc_input_x: 3
  nc_input_y: 1
  nc_output: 3
  ngf: 8
  enc_max_depth: 2
  dec_max_depth: 2
## optimization options
# maximum number of training epochs
max_epoch: 25
# batch size
batch_size: 2
# weight decay
weight_decay: 0.0001
# Adam parameter beta1
beta1: 0.5
# Adam parameter beta2
beta2: 0.999
# initialization [gaussian/kaiming/xavier/orthogonal]
init: kaiming
# initial learning rate
lr: 0.001
# learning rate scheduler
lr_policy: step
# frequency to decay learning rate
step_size: 20000
# magnitude to decay learning rate
gamma: 0.8
# weight for face reconstruction loss
recon_w: 10
# weight for gan adversarial loss
gan_w: 1
# weight for vgg loss
vgg_w: [1, 1, 1, 1]
# path of vgg16 weights path
vgg_model_path: ./vgg_model/vgg16.weight

## dataset option
# worker threads
num_workers: 8
# use memory cached
use_mc: False

### Training & Testing (end)
