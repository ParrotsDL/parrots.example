lr: 0.128
num_gpus: 32
local_batch_size: 64 # 原论文TPU 128，但连V100只能撑到64，为此学习率要相应调整
image_size: 512
label_smooth: 0.0
search_space: big_nas_model_paper
common_setting: ${search_space}/epoch${num_epochs}_half-bs_aug-${augment}_lsm${label_smooth}_drop${network.main.kwargs.dropout}_no-syncbn
all_num_epochs:
    super_learn: 200
    single_search: 200
network:
    names: [main]
    main:
        name: super_net
        kwargs:
            search_space: configs/search/${search_space}.yaml
            zero_gamma: true
            num_classes: '@{num_classes}'
            seed: '@{seed}'
            dropout: 0.0
        init: default
        ckpt: null
optimizer:
    main:
        name: RMSprop
        kwargs:
            lr: 0 # 交给scheduler控制
            weight_decay: 0.00001
            alpha: 0.9
            momentum: 0.9
            eps: 0.03162277660168379 # 0.001 ** 0.5
            nesterov: _ALPHATRION_DELETE_CONFIG_
        param_groups: bias_bn_no_decay
scheduler:
    names: [lr]
    lr:
        name: ExponentialScheduler
        unit_length: epoch
        kwargs:
            base_value: '@{lr}'
            total_steps: '@{num_epochs}'
            gamma: 0.011772749787551084 # 0.97 ** (350 / 2.4)，不管实际epoch是否350
            min_value: 0.0064 # 0.128 * 5%
            warmup_steps: 5
sandwich:
    num_rand: 2
    mean_grad: false
