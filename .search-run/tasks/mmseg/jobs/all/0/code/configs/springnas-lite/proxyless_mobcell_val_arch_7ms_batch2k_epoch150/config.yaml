common:
    model:
        arch: proxyless_mobile
        kwargs:
            # alloc_code for search 40 epochs
            alloc_code: [0, 1, 0, 0, 0, 5, 1, 1, 1, 8, 1, 1, 1, 6, 1, 3, 6, 5, 4, 7, 7]
            # alloc_code for search 80 epochs
#            alloc_code: [0, 1, 0, 0, 0, 5, 1, 1, 1, 5, 3, 1, 1, 6, 1, 1, 1, 8, 4, 7, 7]
            scale: 1.0

    val_arch: True
    with_latency: True

    # Training setting same as mobilenetV2
    augmentation:
        input_size: 224
        test_resize: 256
        colorjitter: [0.2, 0.2, 0.2, 0.1]

    workers: 3
    batch_size: 64

    lr_scheduler:
        type: COSINE

        base_lr: 0.2
        warmup_lr: 0.8
        warmup_steps: 1250
        min_lr: 0.0
        max_iter: 93750

    optimizer:
        type: SGD
        kwargs:
            momentum: 0.9
            weight_decay: 0.00004
            nesterov: True

    no_wd: True
    label_smooth: 0.1

    arch_optimizer:
        type: Adam
        lr: 0.001
        beta1: 0.0
        beta2: 0.999

    val_freq: 1000
    print_freq: 10

    train_root: /mnt/lustre/share/images/train
    train_source: /mnt/lustre/share/images/meta/train.txt
    val_root: /mnt/lustre/share/images/val
    val_source: /mnt/lustre/share/images/meta/val.txt
    arch_root: /mnt/lustre/share/images/train
    arch_source: /mnt/lustre/share/platform/dataset/datasets/nas-lite/proxyless_dataset/vals.txt
